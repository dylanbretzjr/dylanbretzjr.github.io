[
  {
    "objectID": "projects/cyclistic-case-study/index.html#goal",
    "href": "projects/cyclistic-case-study/index.html#goal",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Goal",
    "text": "Goal\nThe overall goal of the marketing analytics team is this:\n\nDesign marketing strategies aimed at converting casual riders into annual members.\n\nThree questions will guide the future marketing program:\n\nHow do annual members and casual riders use Cyclistic bikes differently?\nWhy would casual riders buy Cyclistic annual memberships?\nHow can Cyclistic use digital media to influence casual riders to become members?\n\nFor this case study, I focused on the first question: How do annual members and casual riders use Cyclistic bikes differently?"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#business-task",
    "href": "projects/cyclistic-case-study/index.html#business-task",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Business Task",
    "text": "Business Task\nTo address this question, I completed the following business task:\n\nAnalyze historical bike trip data to identify trends in how annual members and casual riders use Cyclistic bikes differently."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#data-integrity",
    "href": "projects/cyclistic-case-study/index.html#data-integrity",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Data Integrity",
    "text": "Data Integrity\nIn terms of data integrity, this dataset ROCCCs:\n\nReliableâ€”It is reasonable to assume the data is trustworthy and unbiased for the purposes of this case study.\nOriginalâ€”The data is sourced directly from the City of Chicago and Motivate International Inc., the original owners and operators (first-party source).\nComprehensiveâ€”The data contains the necessary records and fields for this analysis.\nCurrentâ€”The dataset includes historical records for several years, including the relevant records from the past 12 months.\nCitedâ€”The data is made available under a public license from the City of Chicago and Motivate International Inc."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#tools",
    "href": "projects/cyclistic-case-study/index.html#tools",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Tools",
    "text": "Tools\nThe combined dataset contains 5,569,279 rows, making it too large for standard spreadsheet software. (Microsoft Excel is limited to roughly 1 million rows, for example.)\nFor this project, I used Python throughout since itâ€™s super powerful and versatile and can be used end-to-end for cleaning, transformation, analysis, and visualization. Plus, Python is fun, and I wanted to practice using it for data analysis.\nI used Spyder 6 as my IDE because it includes features especially useful for scientific data analysis. My environment uses Python 3.12 with the following core libraries:\n\nnumpy and pandas for data manipulation and analysis\nmatplotlib, seaborn, and plotly for data visualization"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#workflow",
    "href": "projects/cyclistic-case-study/index.html#workflow",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Workflow",
    "text": "Workflow\nTo make things easier, I refactored the workflow into three scripts:\n\n_1_data_cleaning.py\n\nCombines, cleans, and transforms data for analysis, and exports it as a CSV file.\n\n_2_analysis_and_viz.py\n\nPerforms statistical analysis and generates static visualizations.\n\n_3_build_ride_map.py\n\nBuilds a dynamic map visualizing ride start and end locations by membership status.\n\n\nIn addition, the project includes a config.py file to define global file paths and a custom .mplstyle file for consistent visualization styling."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#initial-cleaning",
    "href": "projects/cyclistic-case-study/index.html#initial-cleaning",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Initial Cleaning",
    "text": "Initial Cleaning\nWith the data loaded and combined, I proceeded to perform some basic data exploration and cleaning.\n\nCheck Duplicates\nFirst, I checked for duplicate rows and rides, since duplicates could bias the analysis.\ndf.duplicated().sum()\ndf['ride_id'].duplicated().sum()\nNo duplicates were found, so no action was required.\n\n\nDrop Station ID Fields\nNext, I dropped the start_station_id and end_station_id columns.\nThese columns contained inconsistencies due to station ID changes made between May and June 2025. Since station IDs were not required for this analysis anyway (station names and coordinates were sufficient), I dropped both columns to reduce noise and avoid potential confusion later on.\ndf = df.drop(columns=['start_station_id', 'end_station_id'])\n\n\nConvert Timestamps to Datetime\nFinally, I converted the started_at and ended_at columns to pandas datetime objects so I could transform the data using timestamps later in the process.\ndf['started_at'] = pd.to_datetime(df['started_at'])\ndf['ended_at'] = pd.to_datetime(df['ended_at'])"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#handling-missing-values",
    "href": "projects/cyclistic-case-study/index.html#handling-missing-values",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Handling Missing Values",
    "text": "Handling Missing Values\nNext, I performed a null count and found 2,397,565 missing values overall (i.e., empty cells across all columns).\ndf.isna().sum().sum()\nTo understand more, I also performed a null count by column.\ndf.isna().sum()\n\n\n\nColumn\nNull Count\n\n\n\n\nstart_station_name\n1,166,861\n\n\nend_station_name\n1,219,784\n\n\nend_lat\n5,460\n\n\nend_lng\n5,460\n\n\n\n\nDrop Rides Missing End Coordinates\nSince both the end_lat and end_lng columns were missing the exact same number of missing values, I checked whether both values were missing in the same rows by counting the rows missing both end coordinates.\ndf[[\"end_lat\", \"end_lng\"]].isna().all(axis=1).sum()\n5,460 rows were missing values in both the end_lat and end_lng columns, confirming that the missing coordinate data belonged to the same rows.\nThese rows comprised only 0.1% of the dataset, so dropping them wonâ€™t have a significant impact on the analysis. Therefore, I dropped them in order to be able to use the remaining coordinates for mapping.\n\n\nFill Missing Station Names\nNext, I addressed the missing start and end station names.\nSince so many rows were missing station names, dropping them would likely introduce bias and compromise the analysis.\nInstead, I filled the missing station names with a unique placeholder value (no_station_recorded). This approach preserved ride records while still allowing for aggregate analysis using station names.\ndf['start_station_name'] = (\n    df['start_station_name'].fillna('no_station_recorded')\n)\ndf['end_station_name'] = (\n    df['end_station_name'].fillna('no_station_recorded')\n)"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#validate-timeframe",
    "href": "projects/cyclistic-case-study/index.html#validate-timeframe",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Validate Timeframe",
    "text": "Validate Timeframe\nBefore transforming the data further, I checked whether all trips fell within the intended analysis window (2024-11-01 to 2025-10-31).\nI first checked the minimum and maximum trip start and end timestamps.\ndf[\"started_at\"].min()\ndf[\"started_at\"].max()\ndf[\"ended_at\"].min()\ndf[\"ended_at\"].max()\nThe earliest start date was 2024-10-31, which falls one day before the analysis window.\nI then counted how many rides started before the analysis window.\nlen(df[df['started_at'] &lt; TIMEFRAME_START])\nThere were 33 rides that started before 2024-11-01. These rides all ended after the window started, which explains why they were included in the dataset in the first place.\nTo keep the dataset consistent and avoid their impact on my analysis and visualizations, I dropped these 33 rows."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#drop-rides-affected-by-dst",
    "href": "projects/cyclistic-case-study/index.html#drop-rides-affected-by-dst",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Drop Rides Affected by DST",
    "text": "Drop Rides Affected by DST\nTo validate ride duration values, I first checked for negative-duration rides.\nlen(df[df[\"ride_duration_min\"] &lt; 0])\nThere were 43 rides with negative durations. After investigating these records, I found that they allâ€¦\n\noccurred on the same day (2024-11-03),\nstarted at the same time (between 1 a.m. and 2 a.m.),\nand ended at the same time (between 1 a.m. and 2 a.m.).\n\nThis led me to suspect that the negative-duration rides could have been caused by daylight saving time (DST). I confirmed that Chicago observed DST and that the clocks turned back 1 hour at 2 a.m. on 2024-11-03, which coincided with the negative-duration rides in the dataset.\nWhile there were only 43 rides with negative durations, I couldnâ€™t simply drop them since there were likely other rows affected by the DST time shift.\nBasically, if a ride occurred during the fall time shift window, the calculated ride duration would be 1 hour less than it actually was, causing rides shorter than 1 hour to be negative. And if a ride occurred during the spring time shift window, the calculated ride duration would be 1 hour more than it actually was.\nIn total, 507 rows (0.01%) were affected by DSTâ€”476 in the fall and 31 in the spring. Since so few rows were affected, I dropped them with negligible impact on the findings.\nWhile it also would have been possible to adjust the timestamps and correct these rows, dropping them was the simplest and cleanest approach for this case study, especially considering the negligible loss of data."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#drop-ride-duration-outliers",
    "href": "projects/cyclistic-case-study/index.html#drop-ride-duration-outliers",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Drop Ride Duration Outliers",
    "text": "Drop Ride Duration Outliers\nThe final cleaning step was to inspect the distribution of ride durations for extreme outliers that might not represent real rider behavior.\nFirst, I checked the minimum and maximum ride duration.\ndf['ride_duration_min'].min()\ndf['ride_duration_min'].max()\nThe minimum ride duration was 0.0 minutes, while the maximum ride duration exceeded a day (1499.97 minutes). Neither extreme would likely represent valid trips.\nTo better understand this, I plotted the distribution of ride lengths.\nFull Distribution of Ride Duration:\n\nThe vast majority of rides lasted 1 hour or less.\nHowever, the distribution showed a long right tail of unusually lengthy rides. To make this tail more apparent, I plotted ride frequency on a logarithmic scale.\nFull Distribution of Ride Duration (Log Scale):\n\nOverall, the distribution is heavily right-skewed, with most rides concentrated at shorter durations.\nTo take a closer look at this concentration, I zoomed in on rides under 1 hour.\nDistribution of Ride Duration Under 1 Hour:\n\nAt this scale, there is a noticeable spike in very short rides, with an unusually high count lasting 1 minute or less.\nTo examine this more closely, I zoomed in further to rides under 5 minutes.\nDistribution of Ride Duration Under 5 Minutes:\n\nThis revealed an especially high concentration of rides lasting 30 seconds or less.\nI suspected that the unusually high frequency of extremely short rides may have been caused by false starts (undocking and quickly re-docking a bike in favor of another) or canceled rides. Extremely long rides, on the other hand, may have been caused by docking errors or forgotten rides.\nSince both extremely short and extremely long rides likely do not represent typical rider behavior, I dropped all rides lasting 1 minute or less and all rides lasting 1 day or more.\n142,855 rides lasting 1 minute or less and 207 rides lasting 1 day or more were removed for a total of 143,062 rows, representing 2.57% of the original combined dataset."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#cleaning-summary",
    "href": "projects/cyclistic-case-study/index.html#cleaning-summary",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Cleaning Summary",
    "text": "Cleaning Summary\nTo review, here is a summary of all the steps so far:\n\nLoaded and combined data\n\nTotal records: 5,569,279\n\nChecked for duplicate rows/rides: 0 duplicates\nDropped start_station_id and end_station_id columns\nConverted started_at and ended_at columns to datetime\nChecked for null values: 2,397,565 nulls\nDropped rows missing end coordinates: 5,460 (0.10%)\nFilled missing station names with a placeholder (no_station_recorded)\nDropped rides starting before timeframe: 33 (0.00%)\nTransformed data:\n\nExtracted start date, month, week, day of week, and hour to new columns\nCalculated ride duration in minutes in a new column\n\nDropped rows affected by DST: 507 (0.01%)\nDropped rides 1 minute or less and rides 1 day or more: 143,062 (2.57%)\n\nIn total, 149,062 rows (2.68%) were dropped during cleaning, leaving 5,420,217 rows (over 97%) for analysis."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#export-cleaned-dataset",
    "href": "projects/cyclistic-case-study/index.html#export-cleaned-dataset",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Export Cleaned Dataset",
    "text": "Export Cleaned Dataset\nWith the dataset cleaned and validated, I exported and saved it as a CSV file. This way, Iâ€™ll have a copy of the cleaned data and wonâ€™t have to run the cleaning script every time.\nBefore exporting, I reset the index to ensure row numbers were continuous after manipulating the data.\ndf = df.reset_index(drop=True)\n\ndf.to_csv(config.CLEAN_PATH, index=False)\nSince the dataset is large, I validated the export by re-importing the cleaned CSV and confirming that it matched the dataframe used to create it.\nclean_df = pd.read_csv(\n    config.CLEAN_PATH, parse_dates=['started_at', 'ended_at']\n)\n\ntry:\n    pd.testing.assert_frame_equal(\n        df, clean_df, check_dtype=False, check_exact=False\n    )\n    print('SUCCESS: Dataframes match.')\n    del clean_df\nexcept AssertionError as e:\n    print('WARNING: Dataframes do not match:')\n    print(e)\nThe datasets matched, confirming that the cleaned dataset exported successfully."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#summary-tables",
    "href": "projects/cyclistic-case-study/index.html#summary-tables",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Summary Tables",
    "text": "Summary Tables\nThe first step of the analysis was to create summary tables for each statistic.\nTo start, I created summary tables to calculate the total counts and proportion of rides by membership for the following:\n\nOverallâ€”the entire 12-month period (2024-11-01 to 2025-10-31)\nMonthâ€”per month\nWeekâ€”per week\nWeekdayâ€”per day of week (Sundayâ€“Saturday)\nWeekendâ€”weekday vs weekend\nHourâ€”per hour of day\nBike typeâ€”by bike type (â€˜classicâ€™ or â€˜electricâ€™)\nRound-tripâ€”one-way vs round-trip\n\nsum_overall = get_counts_and_pct(df, ['member_casual'])\n\nsum_month = get_counts_and_pct(\n    df, ['start_month', 'member_casual']\n)\n\nsum_week = get_counts_and_pct(\n    df, ['start_week', 'member_casual']\n)\n\nsum_weekday = get_counts_and_pct(\n    df, ['start_weekday', 'member_casual']\n)\n\nsum_weekend = get_counts_and_pct(\n    df.assign(\n        day_type=np.where(\n            df['start_weekday'].isin([0, 6]), 'Weekend', 'Weekday'\n            )\n    ),\n    ['day_type', 'member_casual']\n)\n\nsum_hour = get_counts_and_pct(\n    df, ['start_hour', 'member_casual']\n)\n\nsum_biketype = get_counts_and_pct(\n    df, ['rideable_type', 'member_casual']\n)\n\nsum_roundtrip = get_counts_and_pct(\n    df.assign(\n        is_roundtrip=df['start_station_name'] == df['end_station_name']\n    ),\n    ['is_roundtrip', 'member_casual']\n)\nIn order to visualize the percent change per month by membership, I calculated this in a new column in the monthly counts and percentages summary table (sum_month).\nsum_month['pct_change'] = (\n    sum_month\n    .groupby('member_casual')['count']\n    .pct_change() * 100\n)\nNext, I calculated ride duration statistics (min, max, mean, median, mode, Q1, Q3, IQR) by membership status for the following:\n\nOverallâ€”the entire 12-month period (2024-11-01 to 2025-10-31)\nMonthâ€”per month\nWeekdayâ€”per day of week (Sundayâ€“Saturday)\nBike typeâ€”by bike type (â€˜classicâ€™ or â€˜electricâ€™)\n\nstats_aggs = {\n    'min': 'min',\n    'max': 'max',\n    'mean': 'mean',\n    'median': 'median',\n    'mode': lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan,\n    'q1': lambda x: x.quantile(0.25),\n    'q3': lambda x: x.quantile(0.75),\n    'iqr': lambda x: x.quantile(0.75) - x.quantile(0.25)\n}\n\nduration_overall = (\n    df.groupby('member_casual')['ride_duration_min']\n    .agg(**stats_aggs).reset_index()\n)\n\nduration_month = (\n    df.groupby(['start_month', 'member_casual'])['ride_duration_min']\n    .agg(**stats_aggs).reset_index()\n)\n\nduration_weekday = (\n    df.groupby(['start_weekday', 'member_casual'])['ride_duration_min']\n    .agg(**stats_aggs).reset_index()\n)\n\nduration_biketype = (\n    df.groupby(['rideable_type', 'member_casual'])['ride_duration_min']\n    .agg(**stats_aggs).reset_index()\n)\nI also found the mode start day of week (most popular day) by membership status:\nmode_weekday = (\n    df.pivot_table(\n        index='member_casual',\n        values='start_weekday',\n        aggfunc=lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n        margins=True,\n        margins_name='overall'\n    )\n    .rename(columns={'start_weekday': 'mode_weekday'})\n    .reset_index()\n)\nThen, I found the top stations, routes (station-to-station pairs), and round-trips (same start and end station) for both members and casual riders.\n# Top stations\ntop_start_m = get_ranking(df, ['start_station_name'], 'member')\ntop_start_c = get_ranking(df, ['start_station_name'], 'casual')\n\ntop_end_m = get_ranking(df, ['end_station_name'], 'member')\ntop_end_c = get_ranking(df, ['end_station_name'], 'casual')\n\n# Top routes\ntop_routes_m = get_ranking(\n    df, ['start_station_name', 'end_station_name'], 'member'\n)\ntop_routes_c = get_ranking(\n    df, ['start_station_name', 'end_station_name'], 'casual'\n)\n\n# Top round-trips\nis_roundtrip = df['start_station_name'] == df['end_station_name']\n\ntop_roundtrips_m = get_ranking(\n    df[is_roundtrip], ['start_station_name'], 'member'\n)\ntop_roundtrips_c = get_ranking(\n    df[is_roundtrip], ['start_station_name'], 'casual'\n)\nFinally, I calculated the ride density by membership for each hour of each day of the week (Sundayâ€“Saturday) to create the heat maps.\ndensity_day_hour_m = get_ranking(\n    df, ['start_weekday', 'start_hour'], 'member'\n)\n\ndensity_day_hour_c = get_ranking(\n    df, ['start_weekday', 'start_hour'], 'casual'\n)"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#pivot-tables",
    "href": "projects/cyclistic-case-study/index.html#pivot-tables",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Pivot Tables",
    "text": "Pivot Tables\nTo prepare the data for plotting, I created pivot tables from the summary tables created in the previous section.\npivot_monthly_counts = sum_month.pivot(\n    index='start_month',\n    columns='member_casual',\n    values='count'\n)\n\npivot_weekly_counts = (\n    sum_week\n        .pivot(index='start_week', columns='member_casual', values='count')\n        .fillna(0)\n        .sort_index()\n)\n\npivot_monthly_pct_change = (\n    sum_month\n    .pivot(\n        index='start_month',\n        columns='member_casual',\n        values='pct_change'\n    )\n    .sort_index()\n)\n\npivot_weekday_counts = sum_weekday.pivot(\n    index='start_weekday',\n    columns='member_casual',\n    values='count'\n)\n\npivot_weekday_prop = (\n    sum_weekday\n    .pivot(index='start_weekday', columns='member_casual', values='percentage')\n    .reindex(range(7), fill_value=0)\n    .sort_index()\n)\n\npivot_weekend_counts = (\n    sum_weekend\n    .pivot(index='day_type', columns='member_casual', values='count')\n    .reindex(['Weekday', 'Weekend'])\n)\n\npivot_weekend_prop = (\n    sum_weekend\n    .pivot(index='day_type', columns='member_casual', values='percentage')\n    .reindex(['Weekday', 'Weekend'])\n)\n\npivot_hour_counts = (\n    sum_hour\n        .pivot(index='start_hour', columns='member_casual', values='count')\n        .fillna(0)\n        .sort_index()\n)\n\npivot_density_day_hour_m = (\n    density_day_hour_m\n        .pivot(index='start_weekday', columns='start_hour', values='count')\n        .reindex(index=range(7), columns=range(24), fill_value=0)\n)\n\npivot_density_day_hour_c = (\n    density_day_hour_c\n        .pivot(index='start_weekday', columns='start_hour', values='count')\n        .reindex(index=range(7), columns=range(24), fill_value=0)\n)\n\npivot_density_day_hour_m = pivot_density_day_hour_m.div(\n    pivot_density_day_hour_m.sum(axis=1), axis=0\n)\npivot_density_day_hour_c = pivot_density_day_hour_c.div(\n    pivot_density_day_hour_c.sum(axis=1), axis=0\n)\n\npivot_duration_weekday = duration_weekday.pivot(\n    index='start_weekday',\n    columns='member_casual',\n    values='median'\n)\n\npivot_roundtrip_counts = sum_roundtrip.pivot(\n    index='is_roundtrip',\n    columns='member_casual',\n    values='count'\n)\n\npivot_roundtrip_prop = (\n    sum_roundtrip\n    .pivot(index='is_roundtrip', columns='member_casual', values='percentage')\n    .reindex([0, 1])\n)\n\npivot_biketype_counts = sum_biketype.pivot(\n    index='rideable_type',\n    columns='member_casual',\n    values='count'\n)\n\npivot_biketype_prop = (\n    sum_biketype\n    .pivot(index='rideable_type', columns='member_casual', values='percentage')\n)\nNote: No pivot table was needed for sum_overall since the data was ready to be plotted as-is.\nIn addition, I prepared the data for the box plot showing ride duration distribution by membership status.\ndist_duration_overall = (\n    df[['ride_duration_min', 'member_casual']]\n    .assign(membership_group=lambda d: d['member_casual'].map({\n        'member': 'Member',\n        'casual': 'Casual'\n    }))\n    [['ride_duration_min', 'membership_group']]\n)\n\nmedian_values = (\n    dist_duration_overall\n    .groupby('membership_group')['ride_duration_min']\n    .median()\n)"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#key-insights",
    "href": "projects/cyclistic-case-study/index.html#key-insights",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Key Insights",
    "text": "Key Insights\nThe visualizations below summarize the key insights on how members and casual riders use bikes differently.\n\nOverall\nTotal Rides by Membership Status:\n\n\nAnnual members make up the majority of rides overall (65%)\nCasual riders still make up a significant portion (35%)\n\n\n\nSeasonality\nTotal Monthly Rides by Membership Status:\n\n\nRides peaked during warmer months (summer and early fall)\n\nWeekly Proportion of Rides by Membership Status:\n\n\nProportion of casual riders increases during peak riding season\n\nMonthly Percent Change in Rides by Membership Status:\n\n\nOverall positive growth from February through August, with most growth during spring\nHuge spike of casual riders in March (+207% from February)\n\n\n\nDay of Week\nTotal Daily Rides by Membership Status:\n\n\nTotal member rides are higher on weekdays (â€˜nâ€™ shaped)\nThe busiest day for members is Thursday\nTotal casual rides are higher on weekends (â€˜uâ€™ shaped)\nThe busiest day for casual riders is Saturday\n\nProportion of Weekday vs Weekend Rides by Membership Status:\n\n\nProportion of casual riders is higher on weekends\n\n\n\nTime of Day\nTotal Rides per Start Hour by Membership Status:\n\n\nTwo member daily commute spikes at 8 a.m. and 5 p.m.\nMember lunch rush around noon\nCasual rides gradually build throughout the day (until 5 p.m.)\n\nRide Density per Day and Hour by Membership Status:\n\nRide Density per Day and Hour (Members):\n\n\nDistinct â€˜Oâ€™ shape\nMember activity corresponds with weekday commute times and weekend afternoons\n\nRide Density per Day and Hour (Casual Riders):\n\n\nFaint â€˜Oâ€™ shape\nCasual rider activity is more dispersed across time and day\n\n\n\nRide Duration\nDistribution of Ride Durations by Membership Status:\n\n\nCasual riders tend to take slightly longer rides\nMember median ride length is 8.7 minutes\nCasual rider median ride length is 11.9 minutes\n\nMedian Ride Duration per Weekday by Membership Status:\n\n\nMember median ride duration is fairly consistent day-to-day\nCasual riders take longer rides on weekends\n\n\n\nLocation\nTop 10 Start Stations by Membership Status:\n\nTop 10 End Stations by Membership Status:\n\n\nNo overlap between top 10 start or end stations for members and casual riders\nTop start and end stations are consistent\n\n\n\nRound Trips\nTotal One-Way vs Round-Trips by Membership Status:\n\n\nMost trips are one-way (different start and end stations)\n\nProportion of One-Way vs Round-Trips by Membership Status:\n\n\nLarger proportion of casual riders take round trips"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#additional-visuals",
    "href": "projects/cyclistic-case-study/index.html#additional-visuals",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Additional Visuals",
    "text": "Additional Visuals\nThe following visualizations provide additional context and are included for reference.\nDaily Proportion of Rides by Membership Status:\n\nTotal Weekday vs Weekend Rides by Membership Status:\n\nHourly Proportion of Rides by Membership Status:\n\nTotal Classic vs Electric Bike Rides by Membership Status:\n\nProportion of Classic vs Electric Bike Rides by Membership Status:"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#location-map",
    "href": "projects/cyclistic-case-study/index.html#location-map",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "Location Map",
    "text": "Location Map\nTo better compare geographic differences, I created a dynamic, density-weighted point map showing ride start and end locations by membership type using Plotly. I exported it to HTML with custom JavaScript that links the pan and zoom of the maps and adds responsive scaling for different screen sizes.\nRide Locations by Membership Status:\n\n\nMember ride locations are more dispersed, while casual riders tend to cluster near the lakeshore\n\nThe map can be accessed here.\nBecause the map is interactive, you can pan and zoom around to view specific areas."
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#seasonality-1",
    "href": "projects/cyclistic-case-study/index.html#seasonality-1",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "1. Seasonality",
    "text": "1. Seasonality\nInsights:\n\nPeak riding season during summer and early fall\nHigher proportion of casual riders during peak riding season\nHuge spike of casual riders in spring\n\nRecommendation:\n\nIncrease marketing efforts in spring and summer\nOffer seasonal memberships to attract casual riders"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#time-and-day",
    "href": "projects/cyclistic-case-study/index.html#time-and-day",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "2. Time and Day",
    "text": "2. Time and Day\nInsights:\n\nHigher proportion of casual riders on weekends\nCasual rider activity is more dispersed across time and day\n\nRecommendation:\n\nOffer weekend-only memberships to attract casual weekend-only riders\nOffer optional packages during slow times/days"
  },
  {
    "objectID": "projects/cyclistic-case-study/index.html#location-1",
    "href": "projects/cyclistic-case-study/index.html#location-1",
    "title": "Cyclistic Bike-Share Data Analysis with Python Case Study",
    "section": "3. Location",
    "text": "3. Location\nInsights:\n\nTop start and end stations are consistent\nCasual riders tend to cluster near the lakeshore\n\nRecommendation:\n\nTarget areas around the lakeshore and top stations for casual riders"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dylan Bretz Jr.",
    "section": "",
    "text": "Hello ðŸ‘‹\nMy name is Dylan :)\nIâ€™m a musician, problem solver, and lifelong learner transitioning to data analytics.\nI bring a unique blend of analytical, creative, and critical thinking to everything I do.\nIâ€™m currently building my portfolio, obtaining certifications, and refining my technical skills.\nI use Python, SQL, R, JavaScript, HTML/CSS, and Markdown, as well as spreadsheets and Tableau.\nIâ€™m currently seeking Data Analyst roles (remote preferred).\nIâ€™m based in Ohio but open to relocating (esp.Â to PNW ðŸŒ²).\nRecently completed:\n\nCyclistic Bike-Share Data Analysis with Python Case Study\nGoogle Data Analytics Professional Certificate\nGoogle Data Analysis with Python Specialization\nGoogle Data-Driven Decision Making Specialization\n\nOutside of work, I enjoy watching movies, listening to music, reading, spending time outdoors, and healthy living.\nThanks for stopping byâ€”more coming soon!\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "A collection of completed projects and case studies.\n\n\n\n\n\n\n\n\n\n\n\nCyclistic Bike-Share Data Analysis with Python Case Study\n\n\n\ncase study\n\ndata analysis\n\ndata visualization\n\npython\n\netl\n\n\n\n\n\n\n\n\n\n2026-01-19\n\n\nDylan Bretz Jr.\n\n24 min\n\n\n\n\nNo matching items\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Thank you for visiting my site :)\nFeel free to send me a message if youâ€™d like to connect!\n\n\n Back to top"
  }
]